{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Saylani Mass Training Program**\n",
    "### **Cloud Data Engineering Module by Qasim Hassan**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A basice Extract, Transform and Load (ETL) pipeline using web scrapping, pandas and sql"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install icecream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import StringIO\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "from datetime import datetime\n",
    "#from icecream import ic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 0: Maintaining a Log File\n",
    "This step is done to record the logs while performing ETL and it is not neccessary in an ETL Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_progress(message):\n",
    "    \"\"\"This function logs the mentioned message of a given stage of the\n",
    "    code execution to a log file. Function returns nothing\"\"\"\n",
    "\n",
    "    with open('./logs/code_log', 'a') as f:\n",
    "        f.write(f'{datetime.now()}: {message}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1: Extract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract(url, table_attribs):\n",
    "    \"\"\" This function aims to extract the required\n",
    "    information from the website and save it to a data frame. The\n",
    "    function returns the data frame for further processing. \"\"\"\n",
    "\n",
    "    soup = BeautifulSoup(requests.get(url).text, 'html.parser')\n",
    "    table = soup.find('span', string=table_attribs).find_next('table')\n",
    "    df = pd.read_html(StringIO(str(table)))[0]\n",
    "\n",
    "    log_progress('Data extraction complete. Initiating Transformation process')\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2: Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(df, csv_path):\n",
    "    \"\"\" This function accesses the CSV file for exchange rate\n",
    "    information, and adds three columns to the data frame, each\n",
    "    containing the transformed version of Market Cap column to\n",
    "    respective currencies\"\"\"\n",
    "    \n",
    "    exchange_rate = pd.read_csv(csv_path, index_col=0).to_dict()['Rate']\n",
    "    df['MC_GBP_Billion'] = round(df['Market cap (US$ billion)'] * exchange_rate['GBP'], 2)\n",
    "    df['MC_EUR_Billion'] = round(df['Market cap (US$ billion)'] * exchange_rate['EUR'], 2)\n",
    "    df['MC_INR_Billion'] = round(df['Market cap (US$ billion)'] * exchange_rate['INR'], 2)\n",
    "\n",
    "    \n",
    "\n",
    "    log_progress('Data transformation complete. Initiating Loading process')\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 3: Load"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading data to a CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_to_csv(df, output_path):\n",
    "    \"\"\" This function saves the final data frame as a CSV file in\n",
    "    the provided path. Function returns nothing.\"\"\"\n",
    "\n",
    "    df.to_csv(output_path)\n",
    "\n",
    "    log_progress('Data saved to CSV file')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading data to SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_to_db(df, sql_connection, table_name):\n",
    "    \"\"\" This function saves the final data frame to a database\n",
    "    table with the provided name. Function returns nothing.\"\"\"\n",
    "\n",
    "    df.to_sql(table_name, sql_connection, if_exists='replace', index=False)\n",
    "\n",
    "    log_progress('Data loaded to Database as a table, Executing queries')\n",
    "\n",
    "\n",
    "def run_query(query_statement, sql_connection):\n",
    "    \"\"\" This function runs the query on the database table and\n",
    "    prints the output on the terminal. Function returns nothing. \"\"\"\n",
    "\n",
    "    cursor = sql_connection.cursor()\n",
    "    cursor.execute(query_statement)\n",
    "    result = cursor.fetchall()\n",
    "\n",
    "    log_progress('Process Complete')\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Executing Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'extract' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[34], line 10\u001b[0m\n\u001b[0;32m      5\u001b[0m table_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLargest_banks\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m      7\u001b[0m log_progress(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPreliminaries complete. Initiating ETL process\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 10\u001b[0m df \u001b[38;5;241m=\u001b[39m extract(url, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBy market capitalization\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     12\u001b[0m transform(df,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./input/exchange_rate.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     14\u001b[0m load_to_csv(df, output_csv_path)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'extract' is not defined"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    url = 'https://web.archive.org/web/20230908091635/https://en.wikipedia.org/wiki/List_of_largest_banks'\n",
    "    output_csv_path = './ouput/Largest_banks_data.csv'\n",
    "    database_name = './output/Banks.db'\n",
    "    table_name = 'Largest_banks'\n",
    "    \n",
    "    log_progress('Preliminaries complete. Initiating ETL process')\n",
    "    \n",
    "\n",
    "    df = extract(url, 'By market capitalization')\n",
    "\n",
    "    transform(df,'./input/exchange_rate.csv')\n",
    "\n",
    "    load_to_csv(df, output_csv_path)\n",
    "\n",
    "    with sqlite3.connect(database_name) as conn:\n",
    "        load_to_db(df, conn, table_name)\n",
    "\n",
    "        print(run_query('SELECT * FROM Largest_banks', conn))\n",
    "\n",
    "        print(run_query('SELECT AVG(MC_GBP_Billion) FROM Largest_banks', conn))\n",
    "\n",
    "        print(run_query('SELECT \"Bank name\" FROM Largest_banks LIMIT 5', conn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
